# 초기값 설정 문제와 방지 기법

- 잘못된 초기값 설정 – 초기화의 중요성(마찬가지로 sigmiod에서 발생)
    - 초기값에 너무 영향을 받아 초기값에서 벗어나지 못하는 상황이 발생하기도 한다.

## 방지 기법
- **가중치 초기화(Weight Initialization)**
    - 활성화 함수의 입력값이 너무 커지거나 작아지지 않게 만들어주려는 것이 핵심
- 초기화 설정 문제 해결을 위한 Naïve한 방법
    - 표준 정규분포를 이용해 초기화 
    - 표준편차를 0.01로 하는 정규분포로 초기화
        - 표준 정규분포가 양쪽 끝에 몰리는 문제가 발생하여 탄생
- Xavier(자비어) 초기화 방법 + Sigmoid 함수
    - 표준 정규 분포를 입력 개수의 제곱근으로 나누어 줌
    - Sigmoid와 같은 S자 함수의 경우 출력 값들이 정규 분포 형태를 가져야 안정적으로 학습 가능
- Xavier 초기화 방법 + ReLU 함수
    - ReLU 함수에는 Xavier 초기화가 부적합
    - 레이어를 거쳐갈수록 값이 0에 수렴
- He 초기화 방법(RELU)
    - 표준 정규 분포를 입력 개수 절반의 제곱근으로 나누어 줌 `varience = (2/n)^2
    - 10층 레이어에서도 평균과 표준편차가 0 으로 수렴하지 않음

## 적절한 가중치 초기화 방법
    - Sigmoid, tanh의 경우 : Xavier 초기화 방법이 효율적
    - ReLU계의 활성화 함수 사용 시 : Xavier 초기화보다는 He 초기화 방법이 효율적
    - 최근의 대부분의 모델에서는 He 초기화를 주로 선택



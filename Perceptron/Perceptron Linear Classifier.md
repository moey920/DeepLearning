# í¼ì…‰íŠ¸ë¡  ì„ í˜• ë¶„ë¥˜ê¸°

- ë…¼ë¦¬ íšŒë¡œ ì—­í• ì„ ìˆ˜í–‰í•˜ëŠ” í¼ì…‰íŠ¸ë¡ 
    - ì‚¬ëŒì˜ ì‹ ê²½ê³„ : ë‰´ëŸ° - ì‹ ê²½ë§ - ì§€ëŠ¥
    - ë”¥ëŸ¬ë‹ : í¼ì…‰íŠ¸ë¡  - ì¸ê³µ ì‹ ê²½ë§ - ì¸ê³µì§€ëŠ¥

- AND, OR, NAND, NOR ë“± ë…¼ë¦¬íšŒë¡œëŠ” ì„ í˜• ë¶„ë¥˜ë¡œ í•´ê²°í•  ìˆ˜ ìˆë‹¤.(ì‹±ê¸€ ë ˆì´ì–´ í¼ì…‰íŠ¸ë¡ ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆë‹¤.)
- ë‹¨ì¸µ í¼ì…‰íŠ¸ë¡ (Single Layer Perceptron)
    - Input Layerì—ì„œ Output Layerë¡œ ë°”ë¡œ ê²°ê³¼ë¥¼ ë„ì¶œí•  ìˆ˜ ìˆë‹¤.(ì€ë‹‰ì¸µì´ ì—†ë‹¤) == Linear Classfier

## ë…¼ë¦¬ íšŒë¡œì˜ ì •ì˜

> ì¼ì •í•œ ë…¼ë¦¬ ì—°ì‚°ì— ì˜í•´ ì¶œë ¥ì„ ì–»ëŠ” íšŒë¡œë¥¼ ì˜ë¯¸

1. AND gate

| A/B | C |
|:---:|:---:|
| ğŸ/ğŸ | 0 |
| ğŸ/ğŸ | 0 |
| ğŸ/ğŸ | 0 |
| **ğŸ/ğŸ** | **1** |

`Ex) ğ¶ = ğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘ğ‘¡ğ‘–ğ‘œğ‘›(1 âˆ— ğ´ + 1 âˆ— ğµ âˆ’ 1.5)`


2. OR gate

| A/B | C |
|:---:|:---:|
| **ğŸ/ğŸ** | **0** |
| ğŸ/ğŸ | 1 |
| ğŸ/ğŸ | 1 |
| ğŸ/ğŸ | 1 |

`Ex) ğ¶ = ğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘ğ‘¡ğ‘–ğ‘œğ‘›(1 âˆ— ğ´ + 1 âˆ— ğµ âˆ’ 0.5)`

3. NAND gate

| A/B | C |
|:---:|:---:|
| ğŸ/ğŸ | 1 |
| ğŸ/ğŸ | 1 |
| ğŸ/ğŸ | 1 |
| **ğŸ/ğŸ** | **0** |

`Ex) ğ¶ = ğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘ğ‘¡ğ‘–ğ‘œğ‘›((âˆ’1) âˆ— ğ´ + (âˆ’1) âˆ— ğµ + 1.5)`

4. NOR gate

| A/B | C |
|:---:|:---:|
| **ğŸ/ğŸ** | **1** |
| ğŸ/ğŸ | 0 |
| ğŸ/ğŸ | 0 |
| ğŸ/ğŸ | 0 |

`Ex) ğ¶ = ğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘ğ‘¡ğ‘–ğ‘œğ‘›((âˆ’1) âˆ— ğ´ + (âˆ’1) âˆ— ğµ + 0.5)`

- ì…ë ¥ì¸µ(Input Layer) : ì™¸ë¶€ë¡œë¶€í„° ë°ì´í„°ë¥¼ ì…ë ¥ ë°›ëŠ” ì‹ ê²½ë§ ì…êµ¬ì˜ Layer
- ì¶œë ¥ì¸µ(Output Layer) : ëª¨ë¸ì˜ ìµœì¢… ì—°ì‚° ê²°ê³¼ë¥¼ ë‚´ë³´ë‚´ëŠ” ì‹ ê²½ë§ ì¶œêµ¬ì˜ Layer

### í¼ì…‰íŠ¸ë¡ ì„ í™œìš©í•œ ì„ í˜• ë¶„ë¥˜ê¸°

0, 1 ë°ì´í„°ë¥¼ ê³„ì‚°í•˜ë˜ í¼ì…‰íŠ¸ë¡  ë…¼ë¦¬ íšŒë¡œì—ì„œ í™•ì¥
- ì„ í˜• ë¶„ë¥˜ê¸°ë¡œì¨ ë°ì´í„° ë¶„ë¥˜ ê°€ëŠ¥ : 2ì°¨ì› ê³µê°„ì—ì„œ ê°•ì•„ì§€ì™€ ê³ ì–‘ì´ë¥¼ ë¶„ë¥˜

#### AND gateì™€ OR gate êµ¬í˜„

```
import numpy as np

'''
1. AND_gate í•¨ìˆ˜ë¥¼ ì™„ì„±í•˜ì„¸ìš”.

   Step01. ì…ë ¥ê°’ x1ê³¼ x2ì— ê°ê° ê³±í•´ì¤„ ê°€ì¤‘ì¹˜ëŠ”
           0.5, 0.5ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
           
   Step02. AND_gateë¥¼ ë§Œì¡±í•˜ëŠ” Bias ê°’ì„
           ì„¤ì •í•©ë‹ˆë‹¤. ì—¬ëŸ¬ ê°€ì§€ ê°’ì„ ëŒ€ì…í•´ë³´ë©°
           ì ì ˆí•œ Bias ê°’ì„ ì°¾ì•„ë³´ì„¸ìš”.
   
   Step03. ê°€ì¤‘ì¹˜, ì…ë ¥ê°’, Biasë¥¼ ì´ìš©í•˜ì—¬ 
           ì‹ í˜¸ì˜ ì´í•©ì„ êµ¬í•©ë‹ˆë‹¤.
           
   Step04. Step Function í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ 
           AND_gateì˜ ì¶œë ¥ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
'''

def AND_gate(x1, x2):
    
    x = np.array([x1, x2])
    
    weight = np.array([0.5,0.5])
    
    bias = -0.7
    
    y = np.matmul(x, weight) + bias
    
    return Step_Function(y)
    
'''
2. OR_gate í•¨ìˆ˜ë¥¼ ì™„ì„±í•˜ì„¸ìš”.

   Step01. ì…ë ¥ê°’ x1ê³¼ x2ì— ê°ê° ê³±í•´ì¤„ ê°€ì¤‘ì¹˜ëŠ”
           0.5, 0.5ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
           
   Step02. OR_gateë¥¼ ë§Œì¡±í•˜ëŠ” Bias ê°’ì„
           ì„¤ì •í•©ë‹ˆë‹¤. ì—¬ëŸ¬ ê°€ì§€ ê°’ì„ ëŒ€ì…í•´ë³´ë©°
           ì ì ˆí•œ Bias ê°’ì„ ì°¾ì•„ë³´ì„¸ìš”.
   
   Step03. ê°€ì¤‘ì¹˜, ì…ë ¥ê°’, Biasë¥¼ ì´ìš©í•˜ì—¬ 
           ì‹ í˜¸ì˜ ì´í•©ì„ êµ¬í•©ë‹ˆë‹¤.
           
   Step04. Step Function í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ 
           OR_gateì˜ ì¶œë ¥ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
'''

def OR_gate(x1, x2):
    
    x = np.array([x1, x2])
    
    weight = np.array([0.5,0.5])
    
    bias = -0.3
    
    y = np.matmul(x, weight) + bias
    
    return Step_Function(y)

'''
3. ì„¤ëª…ì„ ë³´ê³  Step Functionì„ ì™„ì„±í•©ë‹ˆë‹¤.

   Step01. 0 ë¯¸ë§Œì˜ ê°’ì´ ë“¤ì–´ì˜¤ë©´ 0ì„,
           0 ì´ìƒì˜ ê°’ì´ ë“¤ì–´ì˜¤ë©´ 1ì„
           ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ë¥¼ êµ¬í˜„í•˜ë©´ ë©ë‹ˆë‹¤.
'''
def Step_Function(y):
    
    return 1 if y >= 0 else 0
    
def main():
    
    # AND Gateì™€ OR Gateì— ë„£ì–´ì¤„ Input
    array = np.array([[0,0], [0,1], [1,0], [1,1]])
    
    # AND Gateë¥¼ ë§Œì¡±í•˜ëŠ”ì§€ ì¶œë ¥í•˜ì—¬ í™•ì¸
    print('AND Gate ì¶œë ¥')
    
    for x1, x2 in array:
        print('Input: ',x1, x2, ', Output: ',AND_gate(x1, x2))
    
    # OR Gateë¥¼ ë§Œì¡±í•˜ëŠ”ì§€ ì¶œë ¥í•˜ì—¬ í™•ì¸
    print('\nOR Gate ì¶œë ¥')
    
    for x1, x2 in array:
        print('Input: ',x1, x2, ', Output: ',OR_gate(x1, x2))

if __name__ == "__main__":
    main()
```

#### NAND gateì™€ NOR gate êµ¬í˜„

```
import numpy as np

'''
1. NAND_gate í•¨ìˆ˜ë¥¼ ì™„ì„±í•˜ì„¸ìš”.

   Step01. ì´ì „ ì‹¤ìŠµì„ ì°¸ê³ í•˜ì—¬ ì…ë ¥ê°’ x1ê³¼ x2ë¥¼
           Numpy array í˜•ì‹ìœ¼ë¡œ ì •ì˜í•œ í›„, x1ê³¼ x2ì—
           ê°ê° ê³±í•´ì¤„ ê°€ì¤‘ì¹˜ë„ Numpy array í˜•ì‹ìœ¼ë¡œ 
           ì ì ˆíˆ ì„¤ì •í•´ì£¼ì„¸ìš”.
           
   Step02. NAND_gateë¥¼ ë§Œì¡±í•˜ëŠ” Bias ê°’ì„
           ì ì ˆíˆ ì„¤ì •í•´ì£¼ì„¸ìš”.
           
   Step03. ê°€ì¤‘ì¹˜, ì…ë ¥ê°’, Biasë¥¼ ì´ìš©í•˜ì—¬ 
           ê°€ì¤‘ ì‹ í˜¸ì˜ ì´í•©ì„ êµ¬í•©ë‹ˆë‹¤.
           
   Step04. Step Function í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ 
           NAND_gateì˜ ì¶œë ¥ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
'''

def NAND_gate(x1, x2):
    
    x = np.array([x1, x2])
    
    weight = np.array([-0.5, -0.5])
    
    bias = 0.7
    
    y = np.matmul(x, weight) + bias
    
    return Step_Function(y)

'''
2. NOR_gate í•¨ìˆ˜ë¥¼ ì™„ì„±í•˜ì„¸ìš”.

   Step01. ë§ˆì°¬ê°€ì§€ë¡œ ì…ë ¥ê°’ x1ê³¼ x2ë¥¼ Numpy array 
           í˜•ì‹ìœ¼ë¡œ ì •ì˜í•œ í›„, x1ê³¼ x2ì— ê°ê° ê³±í•´ì¤„
           ê°€ì¤‘ì¹˜ë„ Numpy array í˜•ì‹ìœ¼ë¡œ ì ì ˆíˆ ì„¤ì •í•´ì£¼ì„¸ìš”.
           
   Step02. NOR_gateë¥¼ ë§Œì¡±í•˜ëŠ” Bias ê°’ì„
           ì ì ˆíˆ ì„¤ì •í•´ì£¼ì„¸ìš”.
           
   Step03. ê°€ì¤‘ì¹˜, ì…ë ¥ê°’, Biasë¥¼ ì´ìš©í•˜ì—¬ 
           ê°€ì¤‘ ì‹ í˜¸ì˜ ì´í•©ì„ êµ¬í•©ë‹ˆë‹¤.
           
   Step04. Step Function í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ 
           NOR_gateì˜ ì¶œë ¥ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
'''

def NOR_gate(x1, x2):
    
    x = np.array([x1, x2])
    
    weight = np.array([-0.5, -0.5])
    
    bias = 0.3
    
    y = np.matmul(x, weight) + bias
    
    return Step_Function(y) 

'''
3. ì„¤ëª…ì„ ë³´ê³  Step Functionì„ ì™„ì„±í•©ë‹ˆë‹¤.
   ì• ì‹¤ìŠµì—ì„œ êµ¬í˜„í•œ í•¨ìˆ˜ë¥¼ ê·¸ëŒ€ë¡œ 
   ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

   Step01. 0 ë¯¸ë§Œì˜ ê°’ì´ ë“¤ì–´ì˜¤ë©´ 0ì„,
           0 ì´ìƒì˜ ê°’ì´ ë“¤ì–´ì˜¤ë©´ 1ì„
           ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ë¥¼ êµ¬í˜„í•˜ë©´ ë©ë‹ˆë‹¤.
'''

def Step_Function(y):
    
    return 1 if y >=0 else 0  

def main():
    
    # NANDì™€ NOR Gateì— ë„£ì–´ì¤„ Input
    array = np.array([[0,0], [0,1], [1,0], [1,1]])
    
    # NAND Gateë¥¼ ë§Œì¡±í•˜ëŠ”ì§€ ì¶œë ¥í•˜ì—¬ í™•ì¸
    print('NAND Gate ì¶œë ¥')
    
    for x1, x2 in array:
        print('Input: ',x1, x2, ' Output: ',NAND_gate(x1, x2))
    
    # NOR Gateë¥¼ ë§Œì¡±í•˜ëŠ”ì§€ ì¶œë ¥í•˜ì—¬ í™•ì¸
    print('\nNOR Gate ì¶œë ¥')
    
    for x1, x2 in array:
        print('Input: ',x1, x2, ' Output: ',NOR_gate(x1, x2))

if __name__ == "__main__":
    main()
```

### í¼ì…‰íŠ¸ë¡  ì„ í˜• ë¶„ë¥˜ê¸°ë¥¼ ì´ìš©í•´ ë¶“ê½ƒ ë°ì´í„° ë¶„ë¥˜í•˜ê¸°(1) : sklearn Perceptron í™œìš©

```
import numpy as np
import pandas as pd

# sklearn ëª¨ë“ˆë“¤
from sklearn.datasets import load_iris
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Perceptron

from sklearn.svm import SVC

from elice_utils import EliceUtils
elice_utils = EliceUtils()

np.random.seed(100)

'''
1. iris ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³ , 
   ë¶ˆëŸ¬ì˜¨ ë°ì´í„°ë¥¼ í•™ìŠµìš©, í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ë¡œ 
   ë¶„ë¦¬í•˜ì—¬ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
   
   Step01. ë¶ˆëŸ¬ì˜¨ ë°ì´í„°ë¥¼ í•™ìŠµìš© ë°ì´í„° 80%, 
           í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° 20%ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.
           
           ì¼ê´€ëœ ê²°ê³¼ í™•ì¸ì„ ìœ„í•´ random_stateë¥¼ 
           0ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.        
'''

def load_data():
    
    iris = load_iris()
    
    X = iris.data[:,2:4]
    Y = iris.target
    
    # random_stateë¥¼ ê³ ì •í•˜ì§€ ì•Šìœ¼ë©´ splitì„ í•  ë•Œë§ˆë‹¤ ë°ì´í„°ê°€ randomí•˜ê²Œ ì˜ë¦°ë‹¤.
    # train_test_split í•¨ìˆ˜ëŠ” ì˜ë¯¸ë¥¼ ì´í•´í•˜ê³  ì¨ì•¼í•œë‹¤. ì‹œê³„ì—´ ë°ì´í„°ëŠ” ë¨¼ì € ìŠ¬ë¼ì´ì‹±ì´ í•„ìš”í•˜ë‹¤. ìˆœì„œê°€ ë°”ë€Œê¸° ë•Œë¬¸ì—.
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 0)
    
    return X_train, X_test, Y_train, Y_test
    
'''
2. ì‚¬ì´í‚·ëŸ°ì˜ Perceptron í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ 
   Perceptron ëª¨ë¸ì„ ì •ì˜í•˜ê³ ,
   í•™ìŠµìš© ë°ì´í„°ì— ëŒ€í•´ í•™ìŠµì‹œí‚µë‹ˆë‹¤.
   
   Step01. ì•ì„œ ì™„ì„±í•œ í•¨ìˆ˜ë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
   
   Step02. Perceptron ëª¨ë¸ì„ ì •ì˜í•©ë‹ˆë‹¤.
           max_iterì™€ eta0ë¥¼ ììœ ë¡­ê²Œ ì„¤ì •í•´ë³´ì„¸ìš”.
   
   Step03. í•™ìŠµìš© ë°ì´í„°ì— ëŒ€í•´ ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤.
   
   Step04. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ëª¨ë¸ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. 
'''

def main(): 

    X_train, X_test, Y_train, Y_test = load_data()
    
    '''
    sklearnìœ¼ë¡œ í•´ê²°í•˜ê¸°
    '''
    
    perceptron = Perceptron(max_iter = 3000, eta0 = 0.2)
    
    # fit í•¨ìˆ˜ëŠ” í•­ìƒ train ë°ì´í„°ë¥¼ ì¸í’‹ìœ¼ë¡œ ë°›ì•„ ê´€ê³„ë¥¼ ì°¾ì•„ë‚¸ë‹¤.
    perceptron.fit(X_train, Y_train)
    
    pred = perceptron.predict(X_test)
    
    accuracy = accuracy_score(pred, Y_test)
    
    print("Test ë°ì´í„°ì— ëŒ€í•œ ì •í™•ë„ : %0.5f" % accuracy)
    
    return X_train, X_test, Y_train, Y_test, pred

if __name__ == "__main__":
    main()
```

### í¼ì…‰íŠ¸ë¡  ì„ í˜• ë¶„ë¥˜ê¸°ë¥¼ ì´ìš©í•´ ë¶“ê½ƒ ë°ì´í„° ë¶„ë¥˜í•˜ê¸°(2) : pandas DataFrame, sklearn SVM í™œìš©

```
import numpy as np
import pandas as pd

# sklearn ëª¨ë“ˆë“¤
from sklearn.datasets import load_iris
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Perceptron

from sklearn.svm import SVC

from elice_utils import EliceUtils
elice_utils = EliceUtils()

np.random.seed(100)

def main():   
    
    '''
    sklearnì€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì œê³µëœë‹¤. ë°ì´í„°ë¥¼ í™•ì¸í•˜ëŠ” ë¶€ë¶„
    iris = load_iris()
    print(iris.keys())
    print(iris.target[:5]) #[0 0 0 0 0] ê°™ì€ ë°ì´í„°ê°€ ë°˜ë³µë˜ê¸° ë•Œë¬¸ì— ëœë¤í•˜ê²Œ ì„ì–´ì£¼ëŠ” ê²ƒì´ ì¢‹ê² ë‹¤.
    print(iris.feature_names) # ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']
    # print(iris.DESCR) # ë°ì´í„° ì œì‘ìê°€ ì œì‘í•œ ë°ì´í„° ì„¤ëª…ë¬¸ì„ ë³´ì—¬ì¤€ë‹¤.
    print(iris.data.shape) # numpyì˜ shape ì†ì„± ì´ìš© (150, 4)
    print(iris.target.shape) # (150,)
    '''
    
    '''
    numpy ë°°ì—´ì„ pandas dfë¡œ ë³€í™˜í•˜ê¸°
    '''
    iris = load_iris()
    df_iris = pd.DataFrame(iris.data, columns = iris.feature_names)
    df_iris.columns = ['SL', 'SW', 'PL','PW'] # sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
    # print(df_iris.head())
    '''
           sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
    0                5.1               3.5                1.4               0.2
    1                4.9               3.0                1.4               0.2
    2                4.7               3.2                1.3               0.2
    3                4.6               3.1                1.5               0.2
    4                5.0               3.6                1.4               0.2
    '''
    
    # ì˜ˆì¸¡í•´ì•¼í•˜ëŠ” yê°’ë„ ì—´ì— ì¶”ê°€í•˜ê¸°
    df_iris['Y'] = iris.target
    # print(df_iris.tail())
    '''
          SL   SW   PL   PW  Y
    145  6.7  3.0  5.2  2.3  2
    146  6.3  2.5  5.0  1.9  2
    147  6.5  3.0  5.2  2.0  2
    148  6.2  3.4  5.4  2.3  2
    149  5.9  3.0  5.1  1.8  2
    '''
    
    # EDA ê³¼ì •
    # print(df_iris.info())
    '''
    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 150 entries, 0 to 149
    Data columns (total 5 columns):
    SL    150 non-null float64
    SW    150 non-null float64
    PL    150 non-null float64
    PW    150 non-null float64
    Y     150 non-null int64
    dtypes: float64(4), int64(1)
    '''
    
    # EDA(2)
    # print(df_iris.describe())
    ''' Feature Scaling : 0~1 ë²”ìœ„ë¡œ ë§ì¶”ëŠ” ê°œë…ì´ í•„ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤
                   SL          SW          PL          PW           Y
    count  150.000000  150.000000  150.000000  150.000000  150.000000(ê° ì—´ì˜ ë°ì´í„°)
    mean     5.843333    3.057333    3.758000    1.199333    1.000000(í‰ê· )
    std      0.828066    0.435866    1.765298    0.762238    0.819232(í‘œì¤€í¸ì°¨)
    min      4.300000    2.000000    1.000000    0.100000    0.000000(ìµœì†Œê°’)
    25%      5.100000    2.800000    1.600000    0.300000    0.000000(1ì‚¬ë¶„ìœ„)
    50%      5.800000    3.000000    4.350000    1.300000    1.000000(ì¤‘ì•™ê°’)
    75%      6.400000    3.300000    5.100000    1.800000    2.000000(3ì‚¬ë¶„ìœ„)
    max      7.900000    4.400000    6.900000    2.500000    2.000000(ìµœëŒ€ê°’)
    '''
    
    # ê²°ì¸¡ì¹˜ê°€ ì¡´ì¬í•  ê²½ìš° ê²°ì¸¡ì¹˜ì˜ ê°œìˆ˜ ì„¸ê¸°
    # print( df_iris.isnull().sum())
    '''
    SL    0
    SW    0
    PL    0
    PW    0
    Y     0
    dtype: int64
    '''
    
    # ì¤‘ë³µê°’ ì°¾ê¸° : í•´ë‹¹ ë°ì´í„°ê°€ ë‘ ë°°ì˜ ì˜í–¥ë ¥ì„ ê°€ì§€ê¸° ë•Œë¬¸ì— ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë–¨ì–´ëœ¨ë¦°ë‹¤.
    # print(df_iris.duplicated().sum()) # duplicated() :ì¤‘ë³µ ë°ì´í„°ê°€ ìˆì„ ê²½ìš° Trueë¥¼ ë°˜í™˜í•œë‹¤
    # 1 
    
    # ì¤‘ë³µê°’ ì œê±°í•˜ê¸°
    df_iris = df_iris.drop_duplicates()
    # print(df_iris.duplicated().sum()) # 0
    # print(df_iris.shape) # (149, 5)
    
    # ìƒê´€ê³„ìˆ˜ í™•ì¸í•˜ê¸°(corrì´ ê° ì—´ì˜ ìƒê´€ê³„ìˆ˜ë¥¼ ê³„ì‚°í•´ì¤€ë‹¤)
    # print(df_iris.corr())
    '''
              SL        SW        PL        PW         Y
    SL  1.000000 -0.118129  0.873738  0.820620  0.786971
    SW -0.118129  1.000000 -0.426028 -0.362894 -0.422987
    PL  0.873738 -0.426028  1.000000  0.962772  0.949402
    PW  0.820620 -0.362894  0.962772  1.000000  0.956514
    Y   0.786971 -0.422987  0.949402  0.956514  1.000000
    '''
    
    # Feature Engineering : íŒŒìƒ ë³€ìˆ˜ ì‚¬ìš©
    df_iris['S_ratio'] = df_iris['SL'] / df_iris['SW']
    df_iris['P_ratio'] = df_iris['PL'] / df_iris['PW']
    # print(df_iris.head())
    '''
        SL   SW   PL   PW  Y   S_ratio  P_ratio
    0  5.1  3.5  1.4  0.2  0  1.457143      7.0
    1  4.9  3.0  1.4  0.2  0  1.633333      7.0
    2  4.7  3.2  1.3  0.2  0  1.468750      6.5
    3  4.6  3.1  1.5  0.2  0  1.483871      7.5
    4  5.0  3.6  1.4  0.2  0  1.388889      7.0
    '''
    
    # ë°ì´í„°í”„ë ˆì„ì„ ì´ìš©í•´ì„œ X, Y ì •ì˜í•˜ê¸°
    X = df_iris.loc[:, 'S_ratio':'P_ratio'] # ëª¨ë“  í–‰ì„ ì„ íƒí•˜ê³ , ì—´ ì¤‘ì—ëŠ” SL, SW, PL, PWë¥¼ ì„ íƒí•œë‹¤, ì–´ë–¤ featureë¥¼ ì´ìš©í•´ ë¶„ì„í•  ê²ƒì¸ì§€ë„ ë¶„ì„ê°€ì˜ ëª«ì´ë‹¤.
    Y = df_iris.loc[:, 'Y'] # ëª¨ë“  í–‰ì„ ì„ íƒí•˜ê³  ì—´ì€ Yë¥¼ ì„ íƒí•œë‹¤
    
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, shuffle = True, random_state = 2021) # random_stateë„ í•™ìŠµë¥ ì— ì˜í–¥ì„ ì£¼ëŠ” íŒŒë¼ë¯¸í„°ì´ë‹¤.
    
    # print(X_train.shape, Y_train.shape) # (119, 4) (119,)
    # print(X_test.shape, Y_test.shape) # (30, 4) (30,)
    
    # SVM ì‚¬ìš©
    svc_model = SVC()
    # ì˜ì‚¬ê²°ì •íŠ¸ë¦¬ ì‚¬ìš©
    dtc_model = DecisionTreeClassifier()
    # ì•™ìƒë¸” - ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ ì‚¬ìš©
    rfc_model = RandomForestClassifier()
    
    svc_model.fit(X_train, Y_train)
    dtc_model.fit(X_train, Y_train)
    rfc_model.fit(X_train, Y_train)
    
    svc_pred = svc_model.predict(X_test)
    dtc_pred = dtc_model.predict(X_test)
    rfc_pred = rfc_model.predict(X_test)
    
    svc_accuracy = accuracy_score(svc_pred, Y_test)
    dtc_accuracy = accuracy_score(dtc_pred, Y_test)
    rfc_accuracy = accuracy_score(rfc_pred, Y_test)
    
    print("SVC Test ë°ì´í„°ì— ëŒ€í•œ ì •í™•ë„ : %0.5f" % svc_accuracy)
    print("DecisionTreeClassifier Test ë°ì´í„°ì— ëŒ€í•œ ì •í™•ë„ : %0.5f" % dtc_accuracy)
    print("RandomForestClassifier Test ë°ì´í„°ì— ëŒ€í•œ ì •í™•ë„ : %0.5f" % rfc_accuracy)


if __name__ == "__main__":
    main()
```


```
    '''
    kerasë¡œ í•´ê²°í•˜ê¸°
    '''
#     perceptron = tf.keras.models.Sequential([
#         tf.keras.layers.Dense(128, activation = 'relu'),
#         tf.keras.layers.Dense(1, activation = 'sigmoid')
#     ])
    
#     perceptron.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
    
#     hist = perceptron.fit(X_train, Y_train, epochs = 20, batch_size = 500, verbose = 2, validation_data = (X_test, Y_test))
    
#     pred = perceptron.evaluate(X_test, Y_test)
    
#     accuracy = accuracy_score(pred, Y_test)
    
#     print("Test ë°ì´í„°ì— ëŒ€í•œ ì •í™•ë„ : %0.5f" % accuracy)
    
#     return X_train, X_test, Y_train, Y_test, pred
```


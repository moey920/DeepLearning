# 다양한 분야의 딥러닝

- 2010년대 딥러닝 호황기의 시작
    - 2012년 AlexNet이 등장하면서 시작됌
    - 2015년 이후(ResNet) 이미지 분류는 딥러닝이 사람의 정확도를 앞서기 시작했다.
- 다양한 딥러닝 적용 사례 존재
    - 특히 이미지, 텍스트와 같은 비정형 데이터에 적용

# 이미지 처리를 위한 딥러닝

- 우리 주변의 이미지 처리 기술 예시
    - 얼굴 인식 카메라 
    - 화질 개선(Super Resolution)
    - 이미지 자동 태깅

- 이미지 분류하기
    - 컴퓨터의 이미지 인식 방법 : 컴퓨터에게 이미지는 각 픽셀 값을 가진 숫자 배열로 인식(픽셀에 rgb, 밝기 등의 값을 가진 데이터) = 텐서

- MLP 기반 신경망의 이미지 처리 방식
    - 극도로 많은 수의 파라미터가 필요
    - 만약 이미지에 변화가 있다면? 강인한 이미지 처리 학습을 어떻게 할 것인가?

## 이미지 처리를 위한 신경망

- 이미지의 특징을 이해할 수 있는 모델이 필요!
    - 합성곱 신경망(Convolution Neural Network)의 등장

- 합성곱 신경망(Convolution Neural Network)
    - 작은 필터를 순환시키는 방식
    - 이미지의 패턴이 아닌 **특징을 중점으로 인식** : 사람이 일일히 특징을 입력하지 않더라도, 딥러닝이 자동으로 Features를 찾아낸다(눈, 코, 입, 귀 등)

### 파이썬에서 이미지 데이터 확인하기

이번 실습에서는 Numpy, PIL, tensorflow.keras 등을 이용하여 이미지를 Numpy 배열로 바꿔보고, 이를 통해 이미지가 어떻게 이루어졌는지 확인해보겠습니다.

- 이미지 데이터를 확인하기 위해 필요한 라이브러리/함수
    - `import PIL` : 이미지를 불러오고 처리하기 위한 라이브러리입니다.
    - `PIL.Image.open(path)` : 이미지를 불러옵니다.
    - `PIL.Image.resize(width,height)` : 이미지의 크기를 조정합니다.

- 결과 :
```
1-1. 'fileName' 이미지(원본)
1-2. Numpy array로 변환된 원본 이미지
1-3. Numpy array로 변환된 원본 이미지의 크기: (500, 333, 3)
2-1. 'fileName' 이미지(resize 후)
2-2. Numpy array로 변환된 resize 후 이미지
2-3. Numpy array로 변환된 resize 후 이미지 크기: (300, 300, 3)
3. Numpy array로 변환된 resize 후 이미지 10장의 크기: (10, 300, 300, 3)
```

```
import  pandas as pd
import numpy as np

import PIL
import matplotlib.image as img
import matplotlib.pyplot as plt

from elice_utils import EliceUtils
elice_utils = EliceUtils()

# 이미지 목록을 불러오는 함수입니다.

def load_data(path):
    return pd.read_csv(path)

'''
1. PIL.Image를 이용하여 
   이름(경로+이름)을 바탕으로 이미지를 불러오고,
   이를 리스트 'images'에 추가하는 함수를 완성합니다.
   main 함수에서 'path'와 'names' 변수를 확인해보세요.
'''

def load_images(path, names):
    
    images=[]
    
    for name in names : # 이미지 파일명의 리스트
        images.append(PIL.Image.open(path + name))
    
    return images

'''
2. 이미지의 사이즈를 main 함수에 있는 'IMG_SIZE'로 
   조정하고, 이를 Numpy 배열로 변환하는 함수를 완성합니다.
'''

def images2numpy(images, size):
    
    output = []
    for image in images :
        output.append(np.array(image.resize(size)))
    
    return output


# 이미지에 대한 정보를 나타내주는 함수입니다.

def sampleVisualize(np_images):

    fileName = "./data/images/1000092795.jpg"
    ndarray = img.imread(fileName)
    
    plt.imshow(ndarray)
    plt.show()    
    plt.savefig("plot.png")
    
    print("\n1-1. 'fileName' 이미지(원본): ")
    elice_utils.send_image("plot.png")
    
    print('\n1-2. Numpy array로 변환된 원본 이미지:', ndarray)
    print('\n1-3. Numpy array로 변환된 원본 이미지의 크기:', np.array(ndarray).shape)
    
    plt.imshow(np_images[0])
    plt.show()
    plt.savefig("plot_re.png")
    
    print("\n2-1. 'fileName' 이미지(resize 후): ")
    elice_utils.send_image("plot_re.png")
    
    print('\n2-2. Numpy array로 변환된 resize 후 이미지:', np_images[0])
    print('\n2-3. Numpy array로 변환된 resize 후 이미지 크기:', np.array(np_images[0]).shape)    
    
    print('\n3. Numpy array로 변환된 resize 후 이미지 10장의 크기:', np.array(np_images).shape)

'''
3. main 함수를 완성하세요.

   Step01. 이미지를 불러오는 함수를 이용해 
           'images'를 정의합니다.
   
   Step02. 이미지를 Numpy 배열로 바꾸는 함수를 이용해
           'np_images'를 정의합니다.
'''

def main():
    
    CSV_PATH = "./data/data.csv"
    IMG_PATH = "./data/images/"
    IMG_SIZE = (300,300)
    MAX_LEN = 30
    BATCH_SIZE = 2
    
    name_caption = load_data(CSV_PATH)
    names = name_caption['file_name']
    
    images = load_images(IMG_PATH, names)
    np_images = images2numpy(images, IMG_SIZE)
    
    sampleVisualize(np_images)
    
    return images, np_images
    
if __name__=='__main__':
    main()
```

### 일반 다층 퍼셉트론 모델(MLP)로 이미지 데이터 분류하기

**MLP in Keras**

MNIST 데이터 셋은 2차원(dimension) 데이터입니다. 따라서 이전 장의 실습들에서도 간단히 말했듯이, 먼저 Flatten 레이어를 활용해 2차원 데이터를 1차원으로 평평하게 만들어주는 과정이 필요합니다. 그 다음 Dense 레이어를 쌓아 다층 퍼셉트론 모델을 만들 수 있습니다.

MLP 모델에서는 2차원 이미지 데이터의 픽셀값을 1차원으로 쭉 피고, 그것을 Dense 레이어에 넣어서 모델을 학습시킵니다. 즉, 이 모델은 이미지의 특성을 학습하는 게 아니라 단순 Numpy 배열의 값만을 학습합니다. 그러면 이미지가 가지고 있는 특성은 의미가 없어지는 걸까요?

**이미지 정규화**

MNIST에서 각각의 이미지는 0~255 사이의 값으로 이루어진 Numpy 배열입니다. 지금까지의 실습을 눈여겨 보셨다면 아실 수 있지만, MNIST 데이터셋을 불러온 후 항상 255로 나누었습니다.

그 이유는 모델이 0~255 사이의 값을 학습하는 것보다 0~1 사이로 정규화된 값을 학습할 때 학습 속도가 더 빨라지고 최적화가 잘 된다는 것이 알려져 있기 때문입니다.

이번 실습을 통해 이미지 정규화도 직접 해보겠습니다.

**원-핫 인코딩(One-hot encoding)**

또한, 지금까지의 실습에선 0-9 사이 값인 label을 그대로 사용해서 MNIST 숫자 분류를 진행했습니다. 즉, 실제값을 그대로 클래스로 이용해서 모델을 평가하고 테스트했습니다.

하지만 이 경우 **자칫 잘못하면 0-9 사이에 ‘순위’가 매겨져** 0은 0으로 label이 매겨졌기에 별로 안 중요하고, 9는 9로 label이 매겨졌기에 아주 중요하다고 모델이 판단할 수 있습니다. 하지만 대부분의 **다중 클래스 분류 문제에선 각 클래스의 관계가 균등**합니다.

이를 해결할 수 있는 방법으로 **‘원-핫 인코딩‘**이 있습니다. 예를 들어 0, 1, 2를 원-핫 인코딩하면 다음과 같습니다.
```
0 -> [1,0,0,0,0,0,0,0,0,0]
1 -> [0,1,0,0,0,0,0,0,0,0]
2 -> [0,0,1,0,0,0,0,0,0,0] …
```
이번 실습에선 원-핫 인코딩을 이용해 label을 클래스화해서 모델에 학습시키겠습니다.

- 결과 :
```
Test Loss : 0.0783 | Test Accuracy : 0.9775000214576721
예측한 Test Data 클래스 :  [7 2 1 ... 4 5 6]
```

```
import numpy as np
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from visual import *

import logging, os
logging.disable(logging.WARNING)
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"

# 동일한 실행 결과 확인을 위한 코드입니다.
np.random.seed(123)
tf.random.set_seed(123)

'''
1. MNIST 데이테 셋을 전처리하는 'preprocess' 함수를 완성합니다.

   Step01. MNIST 데이터 이미지를 
           0~1 사이 값으로 정규화해줍니다.
           원본은 0~255 사이의 값입니다.
           
   Step02. 0~9 사이 값인 label을 클래스화 하기 위해 
           원-핫 인코딩을 진행합니다.
'''

def preprocess():
    
    # MNIST 데이터 세트를 불러옵니다.
    mnist = tf.keras.datasets.mnist
    
    # MNIST 데이터 세트를 Train set과 Test set으로 나누어 줍니다.
    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()    
    
    train_images = train_images / 255.
    test_images = test_images / 255.
    
    train_labels = to_categorical(train_labels, 10)
    test_labels = to_categorical(test_labels, 10)
    
    return train_images, test_images, train_labels, test_labels

'''
2. 다층 퍼셉트론(MLP) 모델을 생성합니다.
'''
def MLP():
    
    model = tf.keras.Sequential()
    model.add(tf.keras.layers.Flatten(input_shape = (28,28))),
    model.add(tf.keras.layers.Dense(128, activation = 'relu')),
    model.add(tf.keras.layers.Dense(64, activation = 'relu')),
    model.add(tf.keras.layers.Dense(10, activation = 'softmax'))
    
    return model
    
'''
3. 모델을 불러온 후 학습시키고 테스트 데이터에 대해 평가합니다.

   Step01. MLP 함수를 통해 모델을 불러옵니다.
   
   Step02. 모델의 손실 함수, 최적화 알고리즘, 
          평가 방법을 설정합니다.
   
   Step03. 모델의 구조를 확인하는 코드를 작성합니다.
   
   Step04. 모델을 학습시킵니다. 검증용 데이터도 설정하세요.
           'epochs'와 'batch_size'도 자유롭게 설정하세요.
              
   Step05. 모델을 테스트하고 손실(loss)값과 
           Test Accuracy 값 및 예측 클래스, 
           손실 함수값 그래프를 출력합니다. 
           
           모델의 성능을 확인해보고,
           목표값을 달성해보세요.
'''

def main():
    
    train_images, test_images, train_labels, test_labels = preprocess()
    
    model = MLP()
    
    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
    
    history = model.fit(train_images, train_labels, epochs = 20, batch_size = 500, validation_data = (test_images, test_labels), verbose = 1)
    
    loss, test_acc = model.evaluate(test_images, test_labels)
    
    print('\nTest Loss : {:.4f} | Test Accuracy : {}'.format(loss, test_acc))
    print('예측한 Test Data 클래스 : ',model.predict_classes(test_images))
    
    Visulaize([('MLP', history)], 'loss')
    
    return history
    
if __name__ == "__main__":
    main()
```
